{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aScgmm8rsFmc",
    "outputId": "5941ceb1-2bd6-4386-cc0c-b15c1922af69"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAnv9_cNsIEj"
   },
   "outputs": [],
   "source": [
    "#for using in google colab\n",
    "!unzip \"drive/MyDrive/train.zip\" -d \"/content/data/\"\n",
    "!unzip \"drive/MyDrive/test.zip\" -d \"/content/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHvUSZblgDIf"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import imageio\n",
    "from IPython.display import display, Image\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np \n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5y1bV92ibq_"
   },
   "outputs": [],
   "source": [
    "train_path = 'data/train/mfcc/'\n",
    "test_path = 'data/test/mfcc/'\n",
    "\n",
    "#ignore .ipynb_checkpoints\n",
    "classes = [f for f in os.listdir(train_path) if not f.startswith('.')]\n",
    "targets = ['yes','no','up','down','left','right','on','off','stop','go','_background_noise_','unknown']\n",
    "# background noise is considered silence for predictions\n",
    "prediction_classes = ['yes','no','up','down','left','right','on','off','stop','go','silence','unknown']\n",
    "\n",
    "#128x87 with 1 channel\n",
    "#expanded to the dimensions required \n",
    "image_shape = (299,299,3)\n",
    "num_classes = len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0qoeBkeXadh"
   },
   "outputs": [],
   "source": [
    "def get_image_names():\n",
    "  images = []\n",
    "  for c in classes:\n",
    "    if c in targets:\n",
    "      label = targets.index(c)\n",
    "    else:\n",
    "      label = targets.index('unknown')\n",
    "    class_path = train_path + c + '/'\n",
    "    class_images = os.listdir(class_path)\n",
    "    labeled = []\n",
    "    for i in class_images:\n",
    "      labeled.append([class_path + i,label])\n",
    "    images.append(labeled)\n",
    "  return images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bF_ltJOXXbaf"
   },
   "outputs": [],
   "source": [
    "def split_names(image_list, num_batches=2):\n",
    "  batches = [[] for _ in range(num_batches)]\n",
    "  for i in image_list:\n",
    "    num = len(i)\n",
    "    random.shuffle(i)\n",
    "    step = num // num_batches \n",
    "    #print(step)\n",
    "    for k in range(0, num_batches):\n",
    "      batches[k].append(i[ k * step : min( (k+1)*step, num) ])\n",
    "  return batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XadCKhgXc63"
   },
   "outputs": [],
   "source": [
    "def make_training_batch(image_names):\n",
    "  train_x, train_y = [], []\n",
    "  # training images are grouped by class\n",
    "  for c in image_names:\n",
    "    for i in c:\n",
    "      #load the image as a np array\n",
    "      x = np.array(imageio.imread(i[0]))\n",
    "      # reshape to a uniform dimension for the model\n",
    "      x = np.expand_dims(x,axis=0)\n",
    "      x = np.resize(x,image_shape)\n",
    "      train_x.append(x)\n",
    "      train_y.append(i[1])\n",
    "  # convert outer lists to np arrays\n",
    "  train_x = np.array(train_x)\n",
    "  train_y = np.array(train_y).reshape(-1,1)\n",
    "  # transform the labels into one-hot vectors \n",
    "  onehot = OneHotEncoder()\n",
    "  train_y = onehot.fit_transform(train_y).toarray()\n",
    "  return (train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBWh9CpzkRcR"
   },
   "outputs": [],
   "source": [
    "def training_loop(num_times=1, num_batches=2, model=None):\n",
    "  # build the model if needed\n",
    "  if model is None:\n",
    "    model = build_model()\n",
    "  \n",
    "  # callbacks used in training\n",
    "  early_stop = EarlyStopping(monitor='val_accuracy',min_delta=.001, patience=5, restore_best_weights=False)\n",
    "  checkpoint = ModelCheckpoint('best_model.h5',monitor='val_accuracy', save_best_only=True,mode='max')\n",
    "\n",
    "  # get filenames  of training images, labeled with their classes\n",
    "  name_list = get_image_names()\n",
    "  for e in range(num_times):\n",
    "    print(\"Loop {}\".format(e))\n",
    "    # divide training data into smaller chunks\n",
    "    # prevents RAM issues with large models and may help with overfitting\n",
    "    name_batches = split_names(name_list, num_batches)\n",
    "\n",
    "    for k in range(num_batches):\n",
    "      print(\"Batch {}\".format(k))\n",
    "      train_x, train_y = make_training_batch(name_batches[k])\n",
    "      shuffler = np.random.permutation(len(train_x))\n",
    "      train_x = train_x[shuffler]\n",
    "      train_y = train_y[shuffler]\n",
    "      model.fit(train_x,train_y,batch_size=50,epochs=20, callbacks=[early_stop,checkpoint], validation_split = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVeEiqkAnjVA"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = keras.applications.InceptionResNetV2(weights=None,classes=num_classes)\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "  model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2NeexLbnB8i",
    "outputId": "d71c9ab3-4593-4405-9a11-a0312f4ff76f"
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "#model = keras.models.load_model(\"drive/MyDrive/best_spectrogram.h5\")\n",
    "training_loop(1,3,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MfuzS8qn_28"
   },
   "outputs": [],
   "source": [
    "def read_test_images(num=1000,image_names=[]):\n",
    "  images = []\n",
    "  names = []\n",
    "  for k in range(min(num,len(image_names))):\n",
    "    if (image_names[k][0] == \".\"):\n",
    "      continue\n",
    "    if (not os.path.exists(test_path + image_names[k])):\n",
    "      continue \n",
    "    names.append(image_names[k])\n",
    "    x = np.array(imageio.imread(test_path + image_names[k]))\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "    x = np.resize(x,image_shape)\n",
    "    images.append(x)\n",
    "  return (names,np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(model, test_x):\n",
    "  predictions = model.predict(test_x)\n",
    "  labels = []\n",
    "  for p in predictions:\n",
    "    i = np.argmax(p)\n",
    "    labels.append(prediction_classes[i])\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dF0LnzG_ZyDB"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "  test_images = os.listdir(test_path)\n",
    "  test_num = len(test_images)\n",
    "  batch_size = 2000\n",
    "  pred_file = open(\"predictions.csv\",\"w\")\n",
    "  pred_file.write(\"fname,label\\n\")\n",
    "  for n in range(0,test_num,batch_size):\n",
    "    image_names, image_batch = read_test_images(batch_size,test_images)\n",
    "    print(n)\n",
    "    label_batch = predict_labels(model,image_batch)\n",
    "    for k in range(min(batch_size,len(image_batch))):\n",
    "      label = label_batch[k]\n",
    "      im = image_names[k].replace(\"png\",\"wav\")\n",
    "      pred_file.write(\"{},{}\\n\".format(im,label))\n",
    "    \n",
    "    test_images = test_images[len(image_batch):]\n",
    "\n",
    "  pred_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DeepCNNSpectrogram.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
