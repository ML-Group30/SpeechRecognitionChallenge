{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aScgmm8rsFmc",
    "outputId": "9f704e50-fcb1-463f-8cd4-36dfce684994"
   },
   "outputs": [],
   "source": [
    "#for using in google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!unzip \"drive/MyDrive/train.zip\" -d \"/content/data/\"\n",
    "!unzip \"drive/MyDrive/test.zip\" -d \"/content/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHvUSZblgDIf"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import imageio\n",
    "from IPython.display import display, Image\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np \n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5y1bV92ibq_"
   },
   "outputs": [],
   "source": [
    "# images directory contains spectrograms, mfcc directory contains MFCCs\n",
    "train_path = 'data/train/images/'\n",
    "test_path = 'data/test/images/'\n",
    "\n",
    "#ignore .ipynb_checkpoints\n",
    "classes = [f for f in os.listdir(train_path) if not f.startswith('.')]\n",
    "targets = ['yes','no','up','down','left','right','on','off','stop','go','silence','unknown']\n",
    "\n",
    "#128x87 with 1 channel, expanded for the model\n",
    "image_shape = (128,87, 3)\n",
    "num_classes = len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0qoeBkeXadh"
   },
   "outputs": [],
   "source": [
    "def get_image_names():\n",
    "  images = []\n",
    "  for c in classes:\n",
    "    #print(c)\n",
    "    if c in targets:\n",
    "      label = targets.index(c)\n",
    "    elif c == '_background_noise_':\n",
    "      label = targets.index('silence')\n",
    "    else: \n",
    "      label = targets.index('unknown')\n",
    "    class_path = train_path + c + '/'\n",
    "    class_images = os.listdir(class_path)\n",
    "    labeled = []\n",
    "    for i in class_images:\n",
    "      labeled.append([class_path + i,label])\n",
    "    images.append(labeled)\n",
    "  return images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bF_ltJOXXbaf"
   },
   "outputs": [],
   "source": [
    "def split_names(image_list, num_batches=2):\n",
    "  batches = [[] for _ in range(num_batches)]\n",
    "  for i in image_list:\n",
    "    num = len(i)\n",
    "    random.shuffle(i)\n",
    "    step = num // num_batches \n",
    "    #print(step)\n",
    "    for k in range(0, num_batches):\n",
    "      batches[k].append(i[ k * step : min( (k+1)*step, num) ])\n",
    "  return batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XadCKhgXc63"
   },
   "outputs": [],
   "source": [
    "def make_training_batch(image_names):\n",
    "  train_x, train_y = [], []\n",
    "  # training images are grouped by class\n",
    "  for c in image_names:\n",
    "    for i in c:\n",
    "      # load the image as a np array\n",
    "      x = np.array(imageio.imread(i[0]))\n",
    "      # flip the image so the first axis is timesteps\n",
    "      x = np.transpose(x)\n",
    "      # split silence clips into smaller chunks \n",
    "      if targets[i[1]] == 'silence':\n",
    "        # number of samples to take from each noise file \n",
    "        num_samples = 100 \n",
    "        for _ in range(num_samples):\n",
    "          start = random.randint(0, x.shape[0] - image_shape[0])\n",
    "          sample = x[start : start + image_shape[0], :]\n",
    "          sample = np.resize(sample, image_shape)\n",
    "          train_x.append(sample)\n",
    "          train_y.append(i[1])\n",
    "      else:\n",
    "        # pad to a uniform size for the model \n",
    "        x = np.resize(x,image_shape)\n",
    "        train_x.append(x)\n",
    "        train_y.append(i[1])\n",
    "  # convert outer lists to np arrays\n",
    "  train_x = np.array(train_x)\n",
    "  train_x = keras.applications.inception_resnet_v2.preprocess_input(train_x)\n",
    "  train_y = np.array(train_y).reshape(-1,1)\n",
    "  # transform the labels into one-hot vectors \n",
    "  onehot = OneHotEncoder()\n",
    "  train_y = onehot.fit_transform(train_y).toarray()\n",
    "  return (train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBWh9CpzkRcR"
   },
   "outputs": [],
   "source": [
    "def training_loop(num_times=1, num_batches=1, num_epochs=50, model=None):\n",
    "  # build the model if needed\n",
    "  if model is None:\n",
    "    model = build_model()\n",
    "  \n",
    "  # callbacks used in training\n",
    "  early_stop = EarlyStopping(monitor='val_accuracy',min_delta=.001, patience=5, restore_best_weights=True)\n",
    "  checkpoint = ModelCheckpoint('best_model.h5',monitor='val_accuracy', save_best_only=True,mode='max')\n",
    "\n",
    "  # get filenames  of training images, labeled with their classes\n",
    "  name_list = get_image_names()\n",
    "  for e in range(num_times):\n",
    "    print(\"Loop {}\".format(e))\n",
    "    # divide training data into smaller chunks\n",
    "    # prevents RAM issues with large models and helps with overfitting\n",
    "    name_batches = split_names(name_list, num_batches)\n",
    "\n",
    "    for k in range(num_batches):\n",
    "      print(\"Batch {}\".format(k))\n",
    "      train_x, train_y = make_training_batch(name_batches[k])\n",
    "      shuffler = np.random.permutation(len(train_x))\n",
    "      train_x = train_x[shuffler]\n",
    "      train_y = train_y[shuffler]\n",
    "      model.fit(train_x,train_y,batch_size=50,epochs=num_epochs, callbacks=[early_stop,checkpoint], validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVeEiqkAnjVA"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.applications.InceptionResNetV2(weights=None,include_top=False, input_shape=(128,87,3)))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(units=num_classes, activation='softmax'))\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "  model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2NeexLbnB8i"
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "#model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rexc193vlEzz"
   },
   "outputs": [],
   "source": [
    "training_loop(num_times=1,num_batches=1,num_epochs=100,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MfuzS8qn_28"
   },
   "outputs": [],
   "source": [
    "def read_test_images(num=1000,image_names=[]):\n",
    "  images = []\n",
    "  names = []\n",
    "  for k in range(min(num,len(image_names))):\n",
    "    if (image_names[k][0] == \".\"):\n",
    "      continue\n",
    "    if (not os.path.exists(test_path + image_names[k])):\n",
    "      continue \n",
    "    names.append(image_names[k])\n",
    "    x = np.array(imageio.imread(test_path + image_names[k]))\n",
    "    x = np.resize(x, image_shape)\n",
    "    #x = np.repeat(x[:, :, np.newaxis], 3, axis=2)\n",
    "    images.append(x)\n",
    "  return (names,np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXoa_fHPveZo"
   },
   "outputs": [],
   "source": [
    "def predict_labels(model, test_x):\n",
    "  predictions = model.predict(test_x)\n",
    "  labels = []\n",
    "  for p in predictions:\n",
    "    i = np.argmax(p)\n",
    "    labels.append(targets[i])\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dF0LnzG_ZyDB"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "  test_images = os.listdir(test_path)\n",
    "  test_num = len(test_images)\n",
    "  batch_size = 2000\n",
    "  pred_file = open(\"predictions.csv\",\"w\")\n",
    "  pred_file.write(\"fname,label\\n\")\n",
    "  for n in range(0,test_num,batch_size):\n",
    "    image_names, image_batch = read_test_images(batch_size,test_images)\n",
    "    print(n)\n",
    "    image_batch = keras.applications.inception_resnet_v2.preprocess_input(image_batch)\n",
    "    label_batch = predict_labels(model,image_batch)\n",
    "    for k in range(min(batch_size,len(image_batch))):\n",
    "      label = label_batch[k]\n",
    "      im = image_names[k].replace(\"png\",\"wav\")\n",
    "      pred_file.write(\"{},{}\\n\".format(im,label))\n",
    "    \n",
    "    test_images = test_images[len(image_batch):]\n",
    "\n",
    "  pred_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHVl9y_uDCyJ"
   },
   "outputs": [],
   "source": [
    "evaluate_model(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Resnet_Spectrogram.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
