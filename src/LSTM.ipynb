{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xt-1GjqDHJp",
    "outputId": "fd6659c6-1b07-42bd-b789-7bbd79952a12"
   },
   "outputs": [],
   "source": [
    "#for using in google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!unzip \"drive/MyDrive/train.zip\" -d \"/content/data/\"\n",
    "!unzip \"drive/MyDrive/test.zip\" -d \"/content/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqERb9crKEy5"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import imageio\n",
    "from IPython.display import display, Image\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np \n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-xk9LE1KHp_"
   },
   "outputs": [],
   "source": [
    "# images directory for spectrograms, mfcc directory for mfccs\n",
    "train_path = 'data/train/images/'\n",
    "test_path = 'data/test/images/'\n",
    "\n",
    "#ignore .ipynb_checkpoints\n",
    "classes = [f for f in os.listdir(train_path) if not f.startswith('.')]\n",
    "targets = ['yes','no','up','down','left','right','on','off','stop','go','silence','unknown']\n",
    "\n",
    "#128x87 with 1 channel\n",
    "#dimensions are flipped so time is the first axis\n",
    "image_shape = (87,128)\n",
    "num_classes = len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHKteUUKKNsE"
   },
   "outputs": [],
   "source": [
    "def get_image_names():\n",
    "  images = []\n",
    "  for c in classes:\n",
    "    #print(c)\n",
    "    if c in targets:\n",
    "      label = targets.index(c)\n",
    "    elif c == '_background_noise_':\n",
    "      label = targets.index('silence')\n",
    "    else: \n",
    "      label = targets.index('unknown')\n",
    "    class_path = train_path + c + '/'\n",
    "    class_images = os.listdir(class_path)\n",
    "    labeled = []\n",
    "    for i in class_images:\n",
    "      labeled.append([class_path + i,label])\n",
    "    images.append(labeled)\n",
    "  return images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NHR9KvGN14p"
   },
   "outputs": [],
   "source": [
    "def split_names(image_list, num_batches=2):\n",
    "  batches = [[] for _ in range(num_batches)]\n",
    "  for i in image_list:\n",
    "    num = len(i)\n",
    "    random.shuffle(i)\n",
    "    step = num // num_batches \n",
    "    #print(step)\n",
    "    for k in range(0, num_batches):\n",
    "      batches[k].append(i[ k * step : min( (k+1)*step, num) ])\n",
    "  return batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2uYdkwaSczX"
   },
   "outputs": [],
   "source": [
    "def make_training_batch(image_names):\n",
    "  train_x, train_y = [], []\n",
    "  # training images are grouped by class\n",
    "  for c in image_names:\n",
    "    for i in c:\n",
    "      # load the image as a np array\n",
    "      x = np.array(imageio.imread(i[0]))\n",
    "      # flip the image so the first axis is timesteps\n",
    "      x = np.transpose(x)\n",
    "      # split silence clips into smaller chunks \n",
    "      if targets[i[1]] == 'silence':\n",
    "        # number of samples to take from the file \n",
    "        num_samples = 100 #x.shape[0] // image_shape[0]\n",
    "        for _ in range(num_samples):\n",
    "          start = random.randint(0, x.shape[0] - image_shape[0])\n",
    "          sample = x[start : start + image_shape[0], :]\n",
    "          train_x.append(sample)\n",
    "          train_y.append(i[1])\n",
    "      else:\n",
    "        # pad to a uniform size for the model \n",
    "        x = np.resize(x,image_shape)\n",
    "        train_x.append(x)\n",
    "        train_y.append(i[1])\n",
    "  # convert outer lists to np arrays\n",
    "  train_x = np.array(train_x)\n",
    "  train_y = np.array(train_y).reshape(-1,1)\n",
    "  # transform the labels into one-hot vectors \n",
    "  onehot = OneHotEncoder()\n",
    "  train_y = onehot.fit_transform(train_y).toarray()\n",
    "  return (train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "btZIIlOioTRS"
   },
   "outputs": [],
   "source": [
    "def training_loop(num_times=1, num_batches=1, num_epochs=50, model=None):\n",
    "  # build the model if needed\n",
    "  if model is None:\n",
    "    model = build_model()\n",
    "  \n",
    "  # callbacks used in training\n",
    "  early_stop = EarlyStopping(monitor='val_accuracy',min_delta=.001, patience=10, restore_best_weights=True)\n",
    "  checkpoint = ModelCheckpoint('best_model.h5',monitor='val_accuracy', save_best_only=True,mode='max')\n",
    "\n",
    "  # get filenames  of training images, labeled with their classes\n",
    "  name_list = get_image_names()\n",
    "  for e in range(num_times):\n",
    "    print(\"Loop {}\".format(e))\n",
    "    # divide training data into smaller chunks if needed\n",
    "    # some large models encountered RAM issues when loading the full data\n",
    "    name_batches = split_names(name_list, num_batches)\n",
    "\n",
    "  # perform training on each batch, using a validation split of 20% and early stopping \n",
    "    for k in range(num_batches):\n",
    "      print(\"Batch {}\".format(k))\n",
    "      train_x, train_y = make_training_batch(name_batches[k])\n",
    "      shuffler = np.random.permutation(len(train_x))\n",
    "      train_x = train_x[shuffler]\n",
    "      train_y = train_y[shuffler]\n",
    "      model.fit(train_x,train_y,batch_size=50,epochs=num_epochs, callbacks=[early_stop,checkpoint], validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqdhmGMSYi_C"
   },
   "outputs": [],
   "source": [
    "# a baseline LSTM architecture for classification\n",
    "def build_baseline():\n",
    "  model = keras.Sequential()\n",
    "  model.add(layers.Input(shape=image_shape))\n",
    "  # first LSTM layer observes the sequence to extract higher-level features \n",
    "  model.add(layers.LSTM(96, activation='tanh', return_sequences=True))\n",
    "  # second LSTM layer observes the sequence from the first to make predictions \n",
    "  model.add(layers.LSTM(64, activation='tanh', return_sequences=False))\n",
    "  # final dense layer predicts class label\n",
    "  model.add(layers.Dense(units=num_classes, activation='softmax',))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8K0RCfGsoRCF"
   },
   "outputs": [],
   "source": [
    "# our best-performing enhancement of the LSTM-based approach\n",
    "def build_best():\n",
    "  # CNN + LSTM model\n",
    "  # two layers of 1D convolutions scan along the time axis\n",
    "  # the resulting sequence is processed by three layers of bidirectional LSTM\n",
    "  # weight regularization is applied to all layers to help with overfitting\n",
    "  # batch normalization is used througout to mitigate internal covariate shift\n",
    "  model = keras.Sequential()\n",
    "  model.add(layers.Input(shape=image_shape))\n",
    "  # features are extracted with two layers of convolution filters\n",
    "  # 1D convolution is used to preserve the time series nature of the data\n",
    "  model.add(layers.Conv1D(filters=128, kernel_size=4, strides=4, \n",
    "            kernel_regularizer=keras.regularizers.l2(1e-5)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Conv1D(filters=128, kernel_size=2, strides=2, \n",
    "            kernel_regularizer=keras.regularizers.l2(1e-5)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  # feature vector sequences are processed by three layers of LSTM\n",
    "  model.add(layers.Bidirectional(layers.LSTM(256, activation='tanh', return_sequences=True,\n",
    "            dropout=0.5, kernel_regularizer=keras.regularizers.l2(1e-5), bias_regularizer=keras.regularizers.l2(1e-4))))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Bidirectional(layers.LSTM(128, activation='tanh', return_sequences=True, \n",
    "            dropout=0.5, kernel_regularizer=keras.regularizers.l2(1e-5), bias_regularizer=keras.regularizers.l2(1e-4))))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Bidirectional(layers.LSTM(96, activation='tanh', return_sequences=False, \n",
    "            dropout=0.5, kernel_regularizer=keras.regularizers.l2(1e-5), bias_regularizer=keras.regularizers.l2(1e-4))))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  # final dense layer predicts class label\n",
    "  model.add(layers.Dense(units=num_classes, activation='softmax',))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxi-vNYMxjzA",
    "outputId": "2dc70234-a1a4-4011-e2a7-c5c03ad2457a"
   },
   "outputs": [],
   "source": [
    "model = build_best()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q13463F_ob1h",
    "outputId": "3e9bd544-1f4b-457e-b6a3-f45a0b4a8ac6"
   },
   "outputs": [],
   "source": [
    "training_loop(num_times=1,num_batches=1,num_epochs=100,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzpLY_UCtba4"
   },
   "outputs": [],
   "source": [
    "def read_test_images(num=2000,image_names=[]):\n",
    "  images = []\n",
    "  names = []\n",
    "  for k in range(min(num,len(image_names))):\n",
    "    if (image_names[k][0] == \".\"):\n",
    "      continue\n",
    "    if (not os.path.exists(test_path + image_names[k])):\n",
    "      continue \n",
    "    names.append(image_names[k])\n",
    "    x = np.array(imageio.imread(test_path + image_names[k]))\n",
    "    x = np.transpose(x)\n",
    "    x = np.resize(x,image_shape)\n",
    "    images.append(x)\n",
    "  return (names,np.array(images))\n",
    "\n",
    "def predict_labels(model, test_x):\n",
    "  predictions = model.predict(test_x)\n",
    "  labels = []\n",
    "  for p in predictions:\n",
    "    i = np.argmax(p)\n",
    "    labels.append(targets[i])\n",
    "  return labels\n",
    "\n",
    "def evaluate_model(model):\n",
    "  test_images = os.listdir(test_path)\n",
    "  test_num = len(test_images)\n",
    "  batch_size = 2000\n",
    "  pred_file = open(\"predictions.csv\",\"w\")\n",
    "  pred_file.write(\"fname,label\\n\")\n",
    "  for n in range(0,test_num,batch_size):\n",
    "    image_names, image_batch = read_test_images(batch_size,test_images)\n",
    "    print(n)\n",
    "    label_batch = predict_labels(model,image_batch)\n",
    "    for k in range(min(batch_size,len(image_batch))):\n",
    "      label = label_batch[k]\n",
    "      im = image_names[k].replace(\"png\",\"wav\")\n",
    "      pred_file.write(\"{},{}\\n\".format(im,label))\n",
    "    \n",
    "    test_images = test_images[len(image_batch):]\n",
    "\n",
    "  pred_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdDb7kxatZoR"
   },
   "outputs": [],
   "source": [
    "evaluate_model(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM_spectrograms.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
