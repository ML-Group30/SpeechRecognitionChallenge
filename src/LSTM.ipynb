{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_spectrograms.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xt-1GjqDHJp",
        "outputId": "b1204f00-8593-4018-e8d3-bb9eacb23420"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slo-NYjhJNoj"
      },
      "source": [
        "#for using in google colab\n",
        "!unzip \"drive/MyDrive/train.zip\" -d \"/content/data/\"\n",
        "!unzip \"drive/MyDrive/test.zip\" -d \"/content/data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqERb9crKEy5"
      },
      "source": [
        "import os \n",
        "import imageio\n",
        "from IPython.display import display, Image\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np \n",
        "import random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-xk9LE1KHp_"
      },
      "source": [
        "train_path = 'data/train/images/'\n",
        "test_path = 'data/test/images/'\n",
        "\n",
        "#ignore .ipynb_checkpoints\n",
        "classes = [f for f in os.listdir(train_path) if not f.startswith('.')]\n",
        "targets = ['yes','no','up','down','left','right','on','off','stop','go','_background_noise_','unknown']\n",
        "# background noise is considered silence for predictions\n",
        "prediction_classes = ['yes','no','up','down','left','right','on','off','stop','go','silence','unknown']\n",
        "\n",
        "#128x87 with 1 channel\n",
        "#dimensions flipped so time is first\n",
        "image_shape = (87,128)\n",
        "num_classes = len(targets)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHKteUUKKNsE"
      },
      "source": [
        "def get_image_names():\n",
        "  images = []\n",
        "  for c in classes:\n",
        "    if c in targets:\n",
        "      label = targets.index(c)\n",
        "    else:\n",
        "      label = targets.index('unknown')\n",
        "    class_path = train_path + c + '/'\n",
        "    class_images = os.listdir(class_path)\n",
        "    labeled = []\n",
        "    for i in class_images:\n",
        "      labeled.append([class_path + i,label])\n",
        "    images.append(labeled)\n",
        "  return images "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NHR9KvGN14p"
      },
      "source": [
        "def split_names(image_list, num_batches=2):\n",
        "  batches = [[] for _ in range(num_batches)]\n",
        "  for i in image_list:\n",
        "    num = len(i)\n",
        "    random.shuffle(i)\n",
        "    step = num // num_batches \n",
        "    #print(step)\n",
        "    for k in range(0, num_batches):\n",
        "      batches[k].append(i[ k * step : min( (k+1)*step, num) ])\n",
        "  return batches "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2uYdkwaSczX"
      },
      "source": [
        "def make_training_batch(image_names):\n",
        "  train_x, train_y = [], []\n",
        "  # training images are grouped by class\n",
        "  for c in image_names:\n",
        "    for i in c:\n",
        "      # load the image as a np array\n",
        "      x = np.array(imageio.imread(i[0]))\n",
        "      # flip the image so the first axis is timesteps\n",
        "      x = np.transpose(x)\n",
        "      # reshape to a uniform dimension for the model\n",
        "      x = np.resize(x,image_shape)\n",
        "      train_x.append(x)\n",
        "      train_y.append(i[1])\n",
        "  # convert outer lists to np arrays\n",
        "  train_x = np.array(train_x)\n",
        "  train_y = np.array(train_y).reshape(-1,1)\n",
        "  # transform the labels into one-hot vectors \n",
        "  onehot = OneHotEncoder()\n",
        "  train_y = onehot.fit_transform(train_y).toarray()\n",
        "  return (train_x, train_y)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btZIIlOioTRS"
      },
      "source": [
        "def training_loop(num_times=1, num_batches=1, num_epochs=50, model=None):\n",
        "  # build the model if needed\n",
        "  if model is None:\n",
        "    model = build_model()\n",
        "  \n",
        "  # callbacks used in training\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy',min_delta=.001, patience=10, restore_best_weights=True)\n",
        "  checkpoint = ModelCheckpoint('best_model.h5',monitor='val_accuracy', save_best_only=True,mode='max')\n",
        "\n",
        "  # get filenames  of training images, labeled with their classes\n",
        "  name_list = get_image_names()\n",
        "  for e in range(num_times):\n",
        "    print(\"Loop {}\".format(e))\n",
        "    # divide training data into smaller chunks\n",
        "    # prevents RAM issues with large models and helps with overfitting\n",
        "    name_batches = split_names(name_list, num_batches)\n",
        "\n",
        "    for k in range(num_batches):\n",
        "      print(\"Batch {}\".format(k))\n",
        "      train_x, train_y = make_training_batch(name_batches[k])\n",
        "      shuffler = np.random.permutation(len(train_x))\n",
        "      train_x = train_x[shuffler]\n",
        "      train_y = train_y[shuffler]\n",
        "      model.fit(train_x,train_y,batch_size=50,epochs=num_epochs, callbacks=[early_stop,checkpoint], validation_split = 0.2)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K0RCfGsoRCF"
      },
      "source": [
        "def build_model():\n",
        "  # CNN + LSTM model\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Input(shape=image_shape))\n",
        "  # features are extracted with two layers of convolution filters\n",
        "  # 1D convolution is used to preserve the time series nature of the data\n",
        "  model.add(layers.Conv1D(filters=128, kernel_size=7, strides=2))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv1D(filters=128, kernel_size=7, strides=2))\n",
        "  # normalization and relu activation\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Activation('relu'))\n",
        "  # feature vector sequences are processed by three layers of LSTM\n",
        "  model.add(layers.Bidirectional(layers.LSTM(128, activation='relu', return_sequences=True, dropout=0.3)))\n",
        "  model.add(layers.Bidirectional(layers.LSTM(128, activation='relu', return_sequences=True, dropout=0.3)))\n",
        "  model.add(layers.Bidirectional(layers.LSTM(128, activation='relu', return_sequences=False, dropout=0.3)))\n",
        "  # final dense layer predicts class label\n",
        "  model.add(layers.Dense(units=num_classes, activation='softmax',))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxi-vNYMxjzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac71068a-c9ab-42cd-a2d7-0006acfbf6b4"
      },
      "source": [
        "model = build_model()\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_8 (Conv1D)            (None, 41, 128)           114816    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 41, 128)           512       \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 18, 128)           114816    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 18, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 18, 128)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_23 (Bidirectio (None, 18, 256)           263168    \n",
            "_________________________________________________________________\n",
            "bidirectional_24 (Bidirectio (None, 18, 256)           394240    \n",
            "_________________________________________________________________\n",
            "bidirectional_25 (Bidirectio (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 12)                3084      \n",
            "=================================================================\n",
            "Total params: 1,285,388\n",
            "Trainable params: 1,284,876\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q13463F_ob1h",
        "outputId": "da4998c3-28e0-4b5d-984d-062093fbb291"
      },
      "source": [
        "training_loop(num_times=1,num_batches=1,num_epochs=50,model=model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loop 0\n",
            "Batch 0\n",
            "Epoch 1/50\n",
            "1036/1036 [==============================] - 250s 232ms/step - loss: 1.1904 - accuracy: 0.6662 - val_loss: 0.4592 - val_accuracy: 0.8619\n",
            "Epoch 2/50\n",
            "1036/1036 [==============================] - 239s 231ms/step - loss: 0.4140 - accuracy: 0.8675 - val_loss: 0.3049 - val_accuracy: 0.9040\n",
            "Epoch 3/50\n",
            "1036/1036 [==============================] - 239s 231ms/step - loss: 0.2939 - accuracy: 0.9053 - val_loss: 0.2595 - val_accuracy: 0.9184\n",
            "Epoch 4/50\n",
            "1036/1036 [==============================] - 241s 232ms/step - loss: 0.2363 - accuracy: 0.9273 - val_loss: 0.2278 - val_accuracy: 0.9295\n",
            "Epoch 5/50\n",
            "1036/1036 [==============================] - 242s 234ms/step - loss: 0.2155 - accuracy: 0.9332 - val_loss: 0.2005 - val_accuracy: 0.9368\n",
            "Epoch 6/50\n",
            "1036/1036 [==============================] - 239s 231ms/step - loss: 0.1855 - accuracy: 0.9424 - val_loss: 0.1627 - val_accuracy: 0.9489\n",
            "Epoch 7/50\n",
            "1036/1036 [==============================] - 239s 230ms/step - loss: 0.1686 - accuracy: 0.9465 - val_loss: 0.1897 - val_accuracy: 0.9409\n",
            "Epoch 8/50\n",
            "1036/1036 [==============================] - 237s 229ms/step - loss: 0.1530 - accuracy: 0.9510 - val_loss: 0.1580 - val_accuracy: 0.9527\n",
            "Epoch 9/50\n",
            "1036/1036 [==============================] - 240s 232ms/step - loss: 0.1386 - accuracy: 0.9564 - val_loss: 0.2135 - val_accuracy: 0.9413\n",
            "Epoch 10/50\n",
            "1036/1036 [==============================] - 240s 232ms/step - loss: 0.1298 - accuracy: 0.9613 - val_loss: 0.1415 - val_accuracy: 0.9569\n",
            "Epoch 11/50\n",
            "1036/1036 [==============================] - 240s 231ms/step - loss: 0.1306 - accuracy: 0.9592 - val_loss: 0.1624 - val_accuracy: 0.9570\n",
            "Epoch 12/50\n",
            "1036/1036 [==============================] - 241s 233ms/step - loss: 0.1187 - accuracy: 0.9611 - val_loss: 0.1483 - val_accuracy: 0.9562\n",
            "Epoch 13/50\n",
            "1036/1036 [==============================] - 241s 233ms/step - loss: 0.1121 - accuracy: 0.9646 - val_loss: 0.1279 - val_accuracy: 0.9635\n",
            "Epoch 14/50\n",
            "1036/1036 [==============================] - 242s 233ms/step - loss: 0.1054 - accuracy: 0.9677 - val_loss: 0.1331 - val_accuracy: 0.9626\n",
            "Epoch 15/50\n",
            "1036/1036 [==============================] - 240s 232ms/step - loss: 0.1000 - accuracy: 0.9681 - val_loss: 0.1340 - val_accuracy: 0.9652\n",
            "Epoch 16/50\n",
            " 556/1036 [===============>..............] - ETA: 1:49 - loss: 0.0894 - accuracy: 0.9715"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzpLY_UCtba4"
      },
      "source": [
        "def read_test_images(num=2000,image_names=[]):\n",
        "  images = []\n",
        "  names = []\n",
        "  for k in range(min(num,len(image_names))):\n",
        "    if (image_names[k][0] == \".\"):\n",
        "      continue\n",
        "    if (not os.path.exists(test_path + image_names[k])):\n",
        "      continue \n",
        "    names.append(image_names[k])\n",
        "    x = np.array(imageio.imread(test_path + image_names[k]))\n",
        "    x = np.transpose(x)\n",
        "    x = np.resize(x,image_shape)\n",
        "    images.append(x)\n",
        "  return (names,np.array(images))\n",
        "\n",
        "def predict_labels(model, test_x):\n",
        "  predictions = model.predict(test_x)\n",
        "  labels = []\n",
        "  for p in predictions:\n",
        "    i = np.argmax(p)\n",
        "    labels.append(prediction_classes[i])\n",
        "  return labels\n",
        "\n",
        "def evaluate_model(model):\n",
        "  test_images = os.listdir(test_path)\n",
        "  test_num = len(test_images)\n",
        "  batch_size = 2000\n",
        "  pred_file = open(\"predictions.csv\",\"w\")\n",
        "  pred_file.write(\"fname,label\\n\")\n",
        "  for n in range(0,test_num,batch_size):\n",
        "    image_names, image_batch = read_test_images(batch_size,test_images)\n",
        "    print(n)\n",
        "    label_batch = predict_labels(model,image_batch)\n",
        "    for k in range(min(batch_size,len(image_batch))):\n",
        "      label = label_batch[k]\n",
        "      im = image_names[k].replace(\"png\",\"wav\")\n",
        "      pred_file.write(\"{},{}\\n\".format(im,label))\n",
        "    \n",
        "    test_images = test_images[len(image_batch):]\n",
        "\n",
        "  pred_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdDb7kxatZoR"
      },
      "source": [
        "evaluate_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}